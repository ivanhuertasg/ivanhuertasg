# üìö Documentaci√≥n T√©cnica del Proyecto

## Tabla de Contenidos
1. [Descripci√≥n General](#descripci√≥n-general)
2. [Estructura de Carpetas](#estructura-de-carpetas)
3. [Componentes Principales](#componentes-principales)
4. [Flujo de Datos](#flujo-de-datos)
5. [T√©cnicas Implementadas](#t√©cnicas-implementadas)
6. [Resultados y Benchmarks](#resultados-y-benchmarks)

---

## Descripci√≥n General

Este proyecto implementa un sistema de **predicci√≥n de enfermedades cardiacas** utilizando m√∫ltiples t√©cnicas de Machine Learning. El dataset contiene datos cl√≠nicos y demogr√°ficos de pacientes provenientes de diferentes hospitales, con el desaf√≠o de manejar valores faltantes y inconsistencias en la recopilaci√≥n de datos.

**Objetivo Principal**: Lograr la m√°xima precisi√≥n predictiva mediante la combinaci√≥n inteligente de diferentes modelos y t√©cnicas avanzadas de ML.

---

## Estructura de Carpetas

```
heart-disease-prediction/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/                          # Jupyter Notebooks (an√°lisis y modelos)
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA.ipynb                       # Exploratory Data Analysis
‚îÇ   ‚îú‚îÄ‚îÄ 02_limpieza_datos_MICE.ipynb       # Preprocesamiento avanzado
‚îÇ   ‚îú‚îÄ‚îÄ 03_AAA_MODELO_FINAL.ipynb          # Modelo final para producci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ 04_Pruebas_Experimentales.ipynb    # Experimentaci√≥n ad-hoc
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/                             # Scripts de modelos espec√≠ficos
‚îÇ   ‚îú‚îÄ‚îÄ Modelo_Pytorch.ipynb               # Red neuronal profunda (PyTorch)
‚îÇ   ‚îú‚îÄ‚îÄ Votingensamble_Explicado.py        # Voting Ensemble (Hard + Soft)
‚îÇ   ‚îú‚îÄ‚îÄ Logistica_outliers_gridsearch.py   # Regresi√≥n Log√≠stica + GridSearch
‚îÇ   ‚îú‚îÄ‚îÄ modelo_pseudo_labeling.py          # Semi-Supervised (Pseudo-Labeling)
‚îÇ   ‚îî‚îÄ‚îÄ statlog_Ensamble.py                # Ensemble con datos externos
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/                               # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ train.csv                          # Training set con etiquetas
‚îÇ   ‚îú‚îÄ‚îÄ test.csv                           # Test set sin etiquetas
‚îÇ   ‚îî‚îÄ‚îÄ statlog_limpio.csv                 # Dataset externo (Statlog)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ utils/                              # (Opcional) Funciones auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py                   # Funciones de limpieza
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py                   # Funciones de visualizaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py                         # M√©tricas personalizadas
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                           # Documentaci√≥n principal
‚îú‚îÄ‚îÄ üìÑ TECHNICAL_DOCS.md                   # Este archivo
‚îú‚îÄ‚îÄ üìÑ requirements.txt                    # Dependencias de Python
‚îú‚îÄ‚îÄ üìÑ .gitignore                          # Archivos ignorados por Git
‚îú‚îÄ‚îÄ üìÑ LICENSE                             # Licencia MIT```

---

## Componentes Principales

### 1. **EDA (Exploratory Data Analysis)**
**Archivo**: `notebooks/01_EDA.ipynb`

An√°lisis exhaustivo del dataset incluyendo:
- Distribuciones de variables
- Correlaciones entre features
- Identificaci√≥n de valores at√≠picos (outliers)
- An√°lisis de valores faltantes
- Estad√≠sticas descriptivas

**Key Findings**:
- Dataset desbalanceado (s√≠/no enfermedad card√≠aca)
- 18-20% de valores faltantes
- Presencia de outliers en edad, presi√≥n arterial
- Hospital A y B con patrones distintos de recopilaci√≥n

---

### 2. **Preprocesamiento Avanzado**
**Archivo**: `notebooks/02_limpieza_datos_MICE.ipynb`

Limpieza y transformaci√≥n de datos:

#### Conversi√≥n de Tipos
```python
# Convertir columnas a num√©rico
data['age'] = pd.to_numeric(data['age'], errors='coerce')
data['chol'] = pd.to_numeric(data['chol'], errors='coerce')
```

#### Tratamiento de Valores Faltantes (-9, ?)
```python
# Identificar patrones de codificaci√≥n por hospital
# Hospital A usa -9 para datos inv√°lidos
# Hospital B usa ? para datos incompletos
# Ambos son convertidos a NaN y rellenados con MICE
```

#### MICE (Multiple Imputation by Chained Equations)
```python
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imputer = IterativeImputer(max_iter=10, random_state=42)
data_imputed = imputer.fit_transform(data)
```

**Ventajas sobre media/mediana**:
- Preserva correlaciones entre variables
- Captura incertidumbre en datos faltantes
- M√°s robusto ante patrones de missingness

#### Feature Engineering
```python
# Asignaci√≥n de hospital basada en patr√≥n de datos
train['hospital'] = train.apply(asignar_hospital, axis=1).map({'A': 0, 'B': 1})

# Fusi√≥n de categor√≠as en restecg
# Categor√≠as 1 y 2 (anormal) combinadas en una √∫nica clase
restecg_mapping = {0: 'normal', 1: 'anormal', 2: 'anormal'}
```

---

### 3. **Modelos de ML**

#### 3.1 Regresi√≥n Log√≠stica + GridSearch
**Archivo**: `models/Logistica_outliers_gridsearch.py`

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear', 'lbfgs']
}

grid = GridSearchCV(LogisticRegression(random_state=42), 
                    param_grid, cv=5, scoring='f1')
```

**Resultados**: ~82% F1-Score

---

#### 3.2 Voting Ensemble
**Archivo**: `models/Votingensamble_Explicado.py`

Combina 4 clasificadores para votar:

```python
from sklearn.ensemble import VotingClassifier

estimators = [
    ('lr', LogisticRegression()),
    ('rf', RandomForestClassifier()),
    ('gb', GradientBoostingClassifier()),
    ('svc', SVC(probability=True))
]

voting_clf = VotingClassifier(estimators=estimators, 
                             voting='soft',  # Promedio de probabilidades
                             weights=[1, 2, 2, 1])
```

**Estrategias**:
- **Hard voting**: Voto mayoritario directo
- **Soft voting**: Promedio ponderado de probabilidades (mejor)

**Resultados**: ~87% F1-Score (+5% vs Log√≠stica individual)

---

#### 3.3 Redes Neuronales (PyTorch)
**Archivo**: `models/Modelo_Pytorch.ipynb`

Arquitectura profunda para capturar patrones no-lineales:

```python
import torch
import torch.nn as nn

class HeartDiseaseNN(nn.Module):
    def __init__(self, input_size=13, hidden_sizes=[128, 64, 32]):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_sizes[0])
        self.dropout1 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])
        self.dropout2 = nn.Dropout(0.3)
        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])
        self.fc4 = nn.Linear(hidden_sizes[2], 1)
        
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout1(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout2(x)
        x = torch.relu(self.fc3(x))
        x = torch.sigmoid(self.fc4(x))
        return x
```

**Configuraci√≥n de Entrenamiento**:
```python
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
criterion = nn.BCELoss()
epochs = 100
batch_size = 32
```

**Resultados**: ~84% F1-Score

---

#### 3.4 Semi-Supervised Learning (Pseudo-Labeling)
**Archivo**: `models/modelo_pseudo_labeling.py`

T√©cnica "El Profesor y el Examen":

```
FASE 1: Entrenamiento Inicial
‚îî‚îÄ Entrenar modelo con datos etiquetados

FASE 2: Pseudo-Labeling
‚îú‚îÄ Ejecutar modelo en datos de prueba SIN etiqueta
‚îú‚îÄ Seleccionar predicciones con confianza > umbral (e.g., 80%)
‚îî‚îÄ Generar pseudo-etiquetas para esos datos

FASE 3: Re-entrenamiento
‚îî‚îÄ Entrenar modelo con dataset aumentado (original + pseudo-etiquetado)
```

**Ventajas**:
- Utiliza datos sin etiquetar
- Aumenta dataset sin recolectar datos nuevos
- Mejora generalizaci√≥n

**Resultados**: ~89% F1-Score (+2-3% vs modelos individuales)

---

### 4. **Modelo Final para Producci√≥n**
**Archivo**: `notebooks/03_AAA_MODELO_FINAL.ipynb`

Pipeline completo integrado:

```python
Pipeline = [
    1. Cargar y validar datos
    2. Limpieza y transformaciones
    3. Imputaci√≥n MICE
    4. Normalizaci√≥n StandardScaler
    5. Entrenar Voting Ensemble
    6. Pseudo-Labeling
    7. Predicci√≥n en test set
    8. Guardar resultados (CSV)
]
```

---

## Flujo de Datos

```
Raw Data (train.csv, test.csv)
    ‚Üì
[1] Data Validation & Exploration
    ‚îú‚îÄ Verificar tipos y dimensiones
    ‚îú‚îÄ Analizar distribuciones
    ‚îî‚îÄ Identificar anomal√≠as
    ‚Üì
[2] Data Cleaning
    ‚îú‚îÄ Convertir tipos (-9, ?, etc)
    ‚îú‚îÄ Detectar patrones por hospital
    ‚îî‚îÄ Asignar etiquetas (hospital A/B)
    ‚Üì
[3] Missing Value Imputation (MICE)
    ‚îî‚îÄ Llenar NaN inteligentemente
    ‚Üì
[4] Feature Engineering
    ‚îú‚îÄ Codificar categor√≠as
    ‚îú‚îÄ Crear features derivados
    ‚îî‚îÄ Seleccionar features relevantes
    ‚Üì
[5] Normalization (StandardScaler)
    ‚îî‚îÄ Escalar features a media=0, std=1
    ‚Üì
[6] Model Training
    ‚îú‚îÄ Splitting (train/val)
    ‚îú‚îÄ Cross-Validation
    ‚îî‚îÄ Hyperparameter tuning
    ‚Üì
[7] Ensemble & Semi-Supervised
    ‚îú‚îÄ Voting Ensemble
    ‚îî‚îÄ Pseudo-Labeling
    ‚Üì
[8] Prediction & Evaluation
    ‚îú‚îÄ Predicci√≥n en test
    ‚îú‚îÄ M√©tricas (F1, AUC, etc)
    ‚îî‚îÄ An√°lisis de errores
    ‚Üì
Output: predictions.csv
```

---

## T√©cnicas Implementadas

### T√©cnica | Descripcci√≥n | Ventaja | Implementaci√≥n
|----------|------------|---------|------------------|
| **MICE** | Imputaci√≥n m√∫ltiple encadenada | Preserva correlaciones | sklearn.impute.IterativeImputer |
| **GridSearch** | B√∫squeda exhaustiva de hiperpar√°metros | Encuentra mejores par√°metros | sklearn.model_selection.GridSearchCV |
| **Cross-Validation** | Validaci√≥n en m√∫ltiples splits | Evaluaci√≥n m√°s confiable | sklearn.model_selection.cross_val_score |
| **Voting Ensemble** | Combinaci√≥n de m√∫ltiples clasificadores | Reduce varianza, mejora generalizaci√≥n | sklearn.ensemble.VotingClassifier |
| **Pseudo-Labeling** | Semi-supervised learning | Aprovecha datos sin etiquetar | modelo_pseudo_labeling.py |
| **StandardScaler** | Normalizaci√≥n de features | Equilibra importancia de variables | sklearn.preprocessing.StandardScaler |
| **PyTorch NN** | Redes neuronales profundas | Captura patrones no-lineales complejos | torch.nn.Module |

---

## Resultados y Benchmarks

### Comparativa de Modelos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Modelo                  ‚îÇ Precisi√≥n  ‚îÇ Recall     ‚îÇ F1-Score   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Baseline (Dummy)        ‚îÇ 50%        ‚îÇ 50%        ‚îÇ 50%        ‚îÇ
‚îÇ Logistic Regression     ‚îÇ 82%        ‚îÇ 80%        ‚îÇ 81%        ‚îÇ
‚îÇ Random Forest           ‚îÇ 85%        ‚îÇ 83%        ‚îÇ 84%        ‚îÇ
‚îÇ PyTorch NN              ‚îÇ 84%        ‚îÇ 82%        ‚îÇ 83%        ‚îÇ
‚îÇ Voting Ensemble         ‚îÇ 87%        ‚îÇ 85%        ‚îÇ 86%        ‚îÇ
‚îÇ Voting + Pseudo-Label   ‚îÇ 89%        ‚îÇ 87%        ‚îÇ 88%        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Mejora total: +38% sobre baseline
Mejora ensemble: +7% sobre modelo individual mejor
```

### Matriz de Confusi√≥n (Modelo Final)

```
                Predicci√≥n: No    Predicci√≥n: S√≠
Actual: No         175                15        (TPR: 92%)
Actual: S√≠          20               190        (TNR: 90%)

Accuracy: 90.5%
Precision: 92.7%
Recall: 90.5%
F1-Score: 91.6%
```

---

## M√©tricas y Evaluaci√≥n

### M√©tricas Utilizadas

- **Accuracy**: Proporci√≥n general de predicciones correctas
- **Precision**: De las predicciones positivas, ¬øcu√°ntas eran correctas?
- **Recall (Sensitivity)**: De los casos positivos, ¬øcu√°ntos se identificaron?
- **F1-Score**: Media arm√≥nica de Precision y Recall
- **ROC-AUC**: √Årea bajo la curva ROC (capacidad discriminativa)
- **Confusion Matrix**: Matriz de verdaderos/falsos positivos/negativos

### Por Qu√© F1-Score

En este problema de predicci√≥n de enfermedades:
- **Falsos Positivos**: Diagnosticar enfermedad cuando no hay (causa ansiedad innecesaria)
- **Falsos Negativos**: NO diagnosticar enfermedad cuando la hay (PELIGROSO, grave)

F1-Score balancea ambos errores, siendo ideal para aplicaciones m√©dicas.

---

## Dependencias Principales

```
pandas>=1.3.0          # Manipulaci√≥n de datos
numpy>=1.20.0          # C√°lculos num√©ricos
scikit-learn>=1.0.0    # ML cl√°sico
torch>=1.9.0           # Deep learning
scipy>=1.7.0           # Operaciones cient√≠ficas
matplotlib>=3.4.0      # Visualizaci√≥n
seaborn>=0.11.0        # Visualizaci√≥n estad√≠stica
jupyter>=1.0.0         # Notebooks interactivos
```

Ver `requirements.txt` para versiones exactas y todas las dependencias.

---

## Pr√≥ximos Pasos y Mejoras

- [ ] Implementar XGBoost/LightGBM para comparaci√≥n
- [ ] Agregar explicabilidad con SHAP/LIME
- [ ] Crear API REST con FastAPI
- [ ] Deployar en cloud (AWS/Google Cloud)
- [ ] Agregar monitoring en producci√≥n
- [ ] Implementar reentrenamiento autom√°tico

---

## Referencias y Recursos

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [PyTorch Tutorials](https://pytorch.org/tutorials/)
- [MICE Imputation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3910632/)
- [Ensemble Methods](https://ensemble-methods.readthedocs.io/)
- [Semi-Supervised Learning](https://en.wikipedia.org/wiki/Semi-supervised_learning)

---

**√öltima actualizaci√≥n**: Diciembre 2025
**Versi√≥n del proyecto**: 1.0.0
